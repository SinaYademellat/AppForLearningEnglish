{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lernkartei_data_structure import Lernkartei_word\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Lernkartei_word in module Lernkartei_data_structure:\n",
      "\n",
      "class Lernkartei_word(builtins.object)\n",
      " |  Lernkartei_word(Txt: str, Collocations: str = None, Status: int = None) -> None\n",
      " |  \n",
      " |   این دیتااستراکچر اصلی کلمات هست  مثل کارت های لغت هست\n",
      " |  برای هر کدام از جعبه هاهم به شکل یک فایل درست ذخیره کردم\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, Txt: str, Collocations: str = None, Status: int = None) -> None\n",
      " |      _summary_\n",
      " |      \n",
      " |      Args:\n",
      " |          Txt (str): _description_\n",
      " |          Status (int):\n",
      " |              day 1  : ==> 1\n",
      " |              day 2  : ==> 2\n",
      " |              day 3  : ==> 3\n",
      " |              week 1 : ==> 4\n",
      " |              week 2 : ==> 5\n",
      " |              Months : ==> 6\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Lernkartei_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mytestfile\\.pkl\n"
     ]
    }
   ],
   "source": [
    "# Exampel for how use diractior for pkl file\n",
    "\n",
    "import os\n",
    "# ----  << set path >> \n",
    "\n",
    "filename = \"mytestfile\"\n",
    "mypath = os.path.join(filename, \".pkl\")\n",
    "print (mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FisrtTimeLoad:\n",
    "    def __init__(self,path_of_pkl_file_as_Db:str) -> None:\n",
    "        \n",
    "        self.Path_for_pkl_file_as_Db = path_of_pkl_file_as_Db\n",
    "\n",
    "        for box_number in range(6):\n",
    "            test_word_is = Lernkartei_word(Txt = f'Txt_box{box_number+1}' ,Collocations=f'Collocations_box{box_number+1}' ,Status=box_number+1)\n",
    "            temp_list   = [test_word_is]\n",
    "\n",
    "            # Saving \n",
    "            # ----  << set path >>             \n",
    "            mypath = os.path.join(path_of_pkl_file_as_Db, f'Box_{box_number+1}.pkl')\n",
    "            # print(mypath) #: db_pkl\\Box_1.pkl\n",
    "            with open(mypath, 'wb') as outp:\n",
    "                pickle.dump(temp_list, outp, pickle.HIGHEST_PROTOCOL)\n",
    "            del temp_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای این مثال یک پوشه در همین جا وجود دارد به اسم \n",
    "<br>\n",
    "db_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file . already exists.\n",
      "Error occurred while processing: ..\n"
     ]
    }
   ],
   "source": [
    "! mkdir db_pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = FisrtTimeLoad('db_pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load one it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_pkl\\Box_1.pkl\n"
     ]
    }
   ],
   "source": [
    "box_number = 1 \n",
    "mypath = os.path.join(A.Path_for_pkl_file_as_Db, f'Box_{box_number}.pkl')\n",
    "print(mypath) #: db_pkl\\Box_1.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "                Txt = Txt_box1\n",
       "                col = Collocations_box1\n",
       "                sta = 1\n",
       "            "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "list_of_Word_is = []\n",
    "with open(mypath, 'rb') as inp:\n",
    "    list_of_Word_is = pickle.load(inp)\n",
    "\n",
    "# -------------------------------\n",
    "print('len: ',len(list_of_Word_is))\n",
    "first_item_is  = list_of_Word_is[0]\n",
    "first_item_is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تست این که درست لود شده اند یا نه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_pkl\\Box_1.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box1\n",
      "                col = Collocations_box1\n",
      "                sta = 1\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "db_pkl\\Box_2.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box2\n",
      "                col = Collocations_box2\n",
      "                sta = 2\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "db_pkl\\Box_3.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box3\n",
      "                col = Collocations_box3\n",
      "                sta = 3\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "db_pkl\\Box_4.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box4\n",
      "                col = Collocations_box4\n",
      "                sta = 4\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "db_pkl\\Box_5.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box5\n",
      "                col = Collocations_box5\n",
      "                sta = 5\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "db_pkl\\Box_6.pkl\n",
      "len:  1\n",
      "\n",
      "                Txt = Txt_box6\n",
      "                col = Collocations_box6\n",
      "                sta = 6\n",
      "            \n",
      "~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for box_number in range(6):\n",
    "\n",
    "        # ----  << set path >>             \n",
    "        mypath = os.path.join(A.Path_for_pkl_file_as_Db, f'Box_{box_number+1}.pkl')\n",
    "        print(mypath) \n",
    "        # break\n",
    "        # Loading\n",
    "        list_of_Word_is = []\n",
    "        with open(mypath, 'rb') as inp:\n",
    "            list_of_Word_is = pickle.load(inp)\n",
    "\n",
    "        # -------------------------------\n",
    "        print('len: ',len(list_of_Word_is))\n",
    "        first_item_is  = list_of_Word_is[0]\n",
    "        print(first_item_is)\n",
    "        print('~'*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
